{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/Soham-Gaonkar/BubbleSegmentation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 0: Imports\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# STEP 1: Custom Dataset for Bubble Images\n",
    "import random\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "import random\n",
    "from torchvision.transforms import functional as TF\n",
    "from torchvision import transforms\n",
    "\n",
    "class BubbleDataset(Dataset):\n",
    "    def __init__(self, image_paths, label_paths, augment=False):\n",
    "        self.image_paths = image_paths\n",
    "        self.label_paths = label_paths\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def center_crop(self, img, target_width=750, target_height=554):\n",
    "        w, h = img.size\n",
    "        left = (w - target_width) // 2\n",
    "        top = (h - target_height) // 2\n",
    "        right = left + target_width\n",
    "        bottom = top + target_height\n",
    "        return img.crop((left, top, right, bottom))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load original image\n",
    "        image = Image.open(self.image_paths[idx]).convert('L')\n",
    "        label = Image.open(self.label_paths[idx])\n",
    "\n",
    "        # Keep copy before any cropping/resizing\n",
    "        original_image = image.copy()  # PIL Image (single-channel)\n",
    "\n",
    "        # Center Crop\n",
    "        image = self.center_crop(image, target_width=750)\n",
    "        label = self.center_crop(label, target_width=750)\n",
    "\n",
    "        # Resize to model input\n",
    "        image = TF.resize(image, (256, 256))\n",
    "        label = TF.resize(label, (256, 256), interpolation=Image.NEAREST)\n",
    "\n",
    "        if self.augment:\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.hflip(image)\n",
    "                label = TF.hflip(label)\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.vflip(image)\n",
    "                label = TF.vflip(label)\n",
    "            if random.random() > 0.5:\n",
    "                angle = random.uniform(-5, 5)\n",
    "                image = TF.rotate(image, angle)\n",
    "                label = TF.rotate(label, angle, interpolation=Image.NEAREST)\n",
    "\n",
    "            # Brightness / Contrast\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.adjust_brightness(image, random.uniform(0.9, 1.1))\n",
    "            if random.random() > 0.5:\n",
    "                image = TF.adjust_contrast(image, random.uniform(0.9, 1.1))\n",
    "\n",
    "            # Random Crop & Resize (mild zoom)\n",
    "            if random.random() > 0.5:\n",
    "                i, j, h, w = transforms.RandomResizedCrop.get_params(\n",
    "                    image, scale=(0.9, 1.0), ratio=(1.0, 1.0))\n",
    "                image = TF.resized_crop(image, i, j, h, w, (256, 256))\n",
    "                label = TF.resized_crop(label, i, j, h, w, (256, 256), interpolation=Image.NEAREST)\n",
    "\n",
    "            # Gaussian Noise\n",
    "            if random.random() > 0.5:\n",
    "                img_tensor = TF.to_tensor(image)\n",
    "                noise = torch.randn_like(img_tensor) * 0.01\n",
    "                img_tensor = (img_tensor + noise).clamp(0, 1)\n",
    "                image = TF.to_pil_image(img_tensor)\n",
    "\n",
    "\n",
    "        image = TF.to_tensor(image)\n",
    "        image = image.expand(3, -1, -1)\n",
    "        label = TF.pil_to_tensor(label).squeeze().long()\n",
    "        label = (label > 127).long()\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# STEP 2: Parsing and Splitting Data Based on Dataset Number\n",
    "all_images = sorted(glob.glob('../Data/US_2/*.jpg'))\n",
    "all_labels = [img_path.replace('US', 'Label').replace('.jpg', '.png') for img_path in all_images]\n",
    "\n",
    "\n",
    "print(\"Sample image:\", all_images[0])\n",
    "print(\"Sample label:\", all_labels[0])\n",
    "\n",
    "img = Image.open(all_images[0])\n",
    "lbl = Image.open(all_labels[0])\n",
    "\n",
    "print(\"Image size:\", img.size)\n",
    "print(\"Label size:\", lbl.size)\n",
    "\n",
    "\n",
    "# Extract dataset number (last digit before .jpg)\n",
    "def extract_dataset_number(path):\n",
    "    return int(path.split('_')[-1].split('.')[0])\n",
    "\n",
    "def extract_pulse_number(path):\n",
    "    return int(path.split('US')[1].split('_')[0])\n",
    "\n",
    "groups = [extract_dataset_number(p) for p in all_images]\n",
    "\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=1/6)\n",
    "print(\"Number of unique groups:\", len(np.unique(groups)))\n",
    "train_idx, val_idx = next(splitter.split(all_images, groups=groups))\n",
    "\n",
    "# train_idx = np.concatenate([train_idx, val_idx])\n",
    "\n",
    "\n",
    "train_images = [all_images[i] for i in train_idx]\n",
    "train_labels = [all_labels[i] for i in train_idx]\n",
    "val_images = [all_images[i] for i in val_idx]\n",
    "val_labels = [all_labels[i] for i in val_idx]\n",
    "\n",
    "\n",
    "\n",
    "print( np.array(set([extract_dataset_number(p) for p in train_images])))\n",
    "print( np.array(set([extract_dataset_number(p) for p in val_images])))\n",
    "\n",
    "print(\"Sample mapping:\")\n",
    "for img, lbl in zip(train_images[:3], train_labels[:3]):\n",
    "    print(f\"{img}  -->  {lbl}\")\n",
    "\n",
    "\n",
    "# STEP 3: Transforms\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "label_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256), interpolation=Image.NEAREST),\n",
    "    transforms.PILToTensor(),\n",
    "    transforms.Lambda(lambda x: x.squeeze().long())\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = BubbleDataset(train_images, train_labels, augment=True)\n",
    "val_dataset = BubbleDataset(val_images, val_labels, augment=False)\n",
    "\n",
    "\n",
    "train_datasets = sorted(set(extract_dataset_number(p) for p in train_images))\n",
    "val_datasets = sorted(set(extract_dataset_number(p) for p in val_images))\n",
    "\n",
    "print(\"Train dataset numbers:\", train_datasets)\n",
    "print(\"Validation dataset numbers:\", val_datasets)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "img_batch, lbl_batch = next(iter(train_loader))\n",
    "print(\"Image shape:\", img_batch.shape)   # [B, 3, 256, 256]\n",
    "print(\"Label shape:\", lbl_batch.shape)   # [B, 256, 256]\n",
    "print(\"Label dtype:\", lbl_batch.dtype)   # should be torch.int64\n",
    "print(\"Label values:\", lbl_batch.unique())  # should be tensor([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(img_batch, lbl_batch, num_samples=5):\n",
    "    plt.figure(figsize=(num_samples * 3, 6))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        img = img_batch[i][0].cpu().numpy()  # take 1st channel directly (no permute needed)\n",
    "        lbl = lbl_batch[i].cpu().numpy()\n",
    "\n",
    "        # Image\n",
    "        plt.subplot(2, num_samples, i + 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Image\")\n",
    "\n",
    "        # Label\n",
    "        plt.subplot(2, num_samples, i + 1 + num_samples)\n",
    "        plt.imshow(lbl, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(\"Label\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "img_batch, lbl_batch = next(iter(train_loader))\n",
    "show_images(img_batch, lbl_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os, glob, re\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# ---- Loss Functions ----\n",
    "class AsymmetricTverskyLoss(nn.Module):\n",
    "    def __init__(self, delta=0.7, smooth=1e-6, class_weights=None):\n",
    "        \"\"\"\n",
    "        delta > 0.5 penalizes false negatives more (good for segmentation)\n",
    "        class_weights: tensor of shape (num_classes,), e.g., [background_weight, foreground_weight]\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "        self.smooth = smooth\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        # preds shape: (batch, num_classes, H, W)\n",
    "        preds = F.softmax(preds, dim=1)  # probability over classes\n",
    "\n",
    "        # Assume binary segmentation: background (0), foreground (1)\n",
    "        foreground_preds = preds[:, 1, :, :]  # shape: (batch, H, W)\n",
    "        background_preds = preds[:, 0, :, :]  # shape: (batch, H, W)\n",
    "\n",
    "        foreground_targets = (targets == 1).float()\n",
    "        background_targets = (targets == 0).float()\n",
    "\n",
    "        # True Positives, False Negatives, False Positives for foreground\n",
    "        true_pos_fg  = (foreground_preds * foreground_targets).sum(dim=[1, 2])\n",
    "        false_neg_fg = (foreground_targets * (1 - foreground_preds)).sum(dim=[1, 2])\n",
    "        false_pos_fg = ((1 - foreground_targets) * foreground_preds).sum(dim=[1, 2])\n",
    "\n",
    "        # True Positives, False Negatives, False Positives for background (optional)\n",
    "        true_pos_bg  = (background_preds * background_targets).sum(dim=[1, 2])\n",
    "        false_neg_bg = (background_targets * (1 - background_preds)).sum(dim=[1, 2])\n",
    "        false_pos_bg = ((1 - background_targets) * background_preds).sum(dim=[1, 2])\n",
    "\n",
    "        # Tversky index for foreground and background\n",
    "        tversky_fg = (true_pos_fg + self.smooth) / (true_pos_fg + self.delta * false_neg_fg + (1 - self.delta) * false_pos_fg + self.smooth)\n",
    "        tversky_bg = (true_pos_bg + self.smooth) / (true_pos_bg + self.delta * false_neg_bg + (1 - self.delta) * false_pos_bg + self.smooth)\n",
    "\n",
    "        if self.class_weights is not None:\n",
    "            # Weighted sum of background and foreground losses\n",
    "            loss = (1 - tversky_bg) * self.class_weights[0] + (1 - tversky_fg) * self.class_weights[1]\n",
    "        else:\n",
    "            # Just use foreground loss if no class weights given\n",
    "            loss = 1 - tversky_fg\n",
    "\n",
    "        return loss  # shape: (batch,)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, reduction='none'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.ce = nn.CrossEntropyLoss(reduction='none')  # always 'none' internally\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        ce_loss = self.ce(preds, targets)  # (batch, H, W)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal = (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        # Apply reduction manually\n",
    "        if self.reduction == 'mean':\n",
    "            return focal.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal.sum()\n",
    "        else:  # 'none' – average over spatial dims per sample\n",
    "            focal = focal.view(focal.shape[0], -1).mean(dim=1)\n",
    "            return focal\n",
    "\n",
    "\n",
    "class AsymmetricFocalTverskyLoss(nn.Module):\n",
    "    def __init__(self, tversky_weight=0.5, focal_weight=0.5, delta=0.3):\n",
    "        super().__init__()\n",
    "        self.tversky = AsymmetricTverskyLoss(delta=delta)\n",
    "        self.focal = FocalLoss(gamma=2, reduction='none')\n",
    "        self.tversky_weight = tversky_weight\n",
    "        self.focal_weight = focal_weight\n",
    "\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        # Compute per-sample losses\n",
    "        tversky_loss = self.tversky(preds, targets)  # shape: (batch,)\n",
    "        focal_loss = self.focal(preds, targets)      # shape: (batch,)\n",
    "        # Weighted sum of the two losses\n",
    "        loss = self.tversky_weight * tversky_loss + self.focal_weight * focal_loss\n",
    "        return loss.mean()  # Return the average over the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        preds = F.softmax(preds, dim=1)[:, 1, :, :]  # Use class 1 (foreground)\n",
    "        targets = (targets == 1).float()\n",
    "        intersection = (preds * targets).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (preds.sum() + targets.sum() + self.smooth)\n",
    "        return 1 - dice\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        ce_loss = self.ce(preds, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal = (1 - pt) ** self.gamma * ce_loss\n",
    "        return focal\n",
    "\n",
    "\n",
    "class DiceFocalLoss(nn.Module):\n",
    "    def __init__(self, dice_weight=0.5, focal_weight=0.5):\n",
    "        super().__init__()\n",
    "        self.dice = DiceLoss()\n",
    "        self.focal = FocalLoss()\n",
    "        self.dice_weight = dice_weight\n",
    "        self.focal_weight = focal_weight\n",
    "\n",
    "    def forward(self, preds, targets):\n",
    "        return self.dice_weight * self.dice(preds, targets) + self.focal_weight * self.focal(preds, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models.segmentation import deeplabv3_resnet101, DeepLabV3_ResNet101_Weights\n",
    "weights = DeepLabV3_ResNet101_Weights.DEFAULT\n",
    "\n",
    "try:\n",
    "    from torchvision.models.segmentation import deeplabv3_resnet101, DeepLabV3_ResNet101_Weights\n",
    "    weights = DeepLabV3_ResNet101_Weights.DEFAULT\n",
    "\n",
    "    model = deeplabv3_resnet101(weights=weights)\n",
    "    model.classifier[4] = nn.Conv2d(256, 2, kernel_size=1)\n",
    "    model = model.cuda()\n",
    "    print(\"✅ Model successfully moved to CUDA\")\n",
    "except Exception as e:\n",
    "    print(\"❌ CUDA error during model setup:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import yaml\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# from datetime import datetime\n",
    "\n",
    "# # --- IoU ---\n",
    "# def compute_class_iou(preds, targets, num_classes):\n",
    "#     ious = []\n",
    "#     total_intersection = 0\n",
    "#     total_union = 0\n",
    "\n",
    "#     for cls in range(num_classes):\n",
    "#         pred_inds = (preds == cls)\n",
    "#         target_inds = (targets == cls)\n",
    "#         intersection = (pred_inds & target_inds).sum().item()\n",
    "#         union = (pred_inds | target_inds).sum().item()\n",
    "\n",
    "#         if union == 0:\n",
    "#             ious.append(float('nan'))  # Undefined IoU\n",
    "#         else:\n",
    "#             ious.append(intersection / union)\n",
    "#             total_intersection += intersection\n",
    "#             total_union += union\n",
    "\n",
    "#     mean_iou = np.nanmean(ious)\n",
    "#     weighted_iou = total_intersection / total_union if total_union != 0 else float('nan')\n",
    "\n",
    "#     return {\n",
    "#         'per_class_iou': ious,\n",
    "#         'mean_iou': mean_iou,\n",
    "#         'weighted_iou': weighted_iou\n",
    "#     }\n",
    "\n",
    "# num_classes =2\n",
    "# # === Config Params === #\n",
    "# experiment_name = f\"BubbleSeg_lr1e-4_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "# save_dir = os.path.join(\"checkpoints\", experiment_name)\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# params = {\n",
    "#     'model': str(model.__class__.__name__),\n",
    "#     'criterion': 'DiceFocalLoss(dice_weight=0.5, focal_weight=0.6))',\n",
    "#     'optimizer': 'Adam',\n",
    "#     'lr': 3e-4,\n",
    "#     'scheduler': 'ReduceLROnPlateau',\n",
    "#     'num_epochs': 2\n",
    "# }\n",
    "\n",
    "# with open(os.path.join(save_dir, \"initial_config.yaml\"), 'w') as f:\n",
    "#     yaml.dump(params, f)\n",
    "\n",
    "# # === Training Setup === #\n",
    "# criterion = DiceFocalLoss(dice_weight=0.5, focal_weight=0.6)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr= 3e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "# num_epochs = 5\n",
    "# best_val_iou = 0\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     train_loss = 0.0\n",
    "\n",
    "#     train_loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\", leave=False)\n",
    "#     for imgs, masks in train_loop:\n",
    "#         imgs, masks = imgs.cuda(), masks.cuda()\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(imgs)['out']\n",
    "#         loss = criterion(outputs, masks)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         train_loss += loss.item()\n",
    "#         train_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "#     avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "#     # === Validation === #\n",
    "#     model.eval()\n",
    "#     val_loss = 0.0\n",
    "#     val_iou = 0.0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for imgs, masks in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "#             imgs, masks = imgs.cuda(), masks.cuda()\n",
    "#             outputs = model(imgs)['out']\n",
    "#             loss = criterion(outputs, masks)\n",
    "#             val_loss += loss.item()\n",
    "\n",
    "#             preds = torch.argmax(outputs, dim=1)\n",
    "#             val_iou += compute_class_iou(preds.cpu(), masks.cpu(), num_classes=num_classes)['mean_iou']\n",
    "\n",
    "#     avg_val_loss = val_loss / len(val_loader)\n",
    "#     avg_val_iou = val_iou / len(val_loader)\n",
    "\n",
    "#     print(f\"📊 Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f} | Val Loss = {avg_val_loss:.4f} | Val IoU = {avg_val_iou:.4f}\")\n",
    "\n",
    "#     scheduler.step(avg_val_iou)\n",
    "\n",
    "#     # === Save per epoch === #\n",
    "#     torch.save(model.state_dict(), os.path.join(save_dir, f\"epoch_{epoch+1}.pth\"))\n",
    "\n",
    "#     # === Save best model === #\n",
    "#     if avg_val_iou > best_val_iou:\n",
    "#         best_val_iou = avg_val_iou\n",
    "#         torch.save(model.state_dict(), os.path.join(save_dir, \"best_model.pth\"))\n",
    "#         print(\"✅ Best model saved!\")\n",
    "\n",
    "# # === Save Final model === #\n",
    "# torch.save(model.state_dict(), os.path.join(save_dir, \"last_model.pth\"))\n",
    "# print(\"🏁 Final model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric.py\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.spatial.distance import directed_hausdorff, cdist\n",
    "from scipy.ndimage import binary_erosion, distance_transform_edt\n",
    "import warnings\n",
    "from config import Config\n",
    "\n",
    "# --- Extract binary boundary map ---\n",
    "def get_boundary(mask):\n",
    "    eroded = binary_erosion(mask, border_value=0)\n",
    "    boundary = mask ^ eroded\n",
    "    return boundary\n",
    "\n",
    "# --- Boundary F1 score (MATLAB-style) ---\n",
    "def compute_bf_score_single(pred, target, tolerance=2):\n",
    "    if pred.sum() == 0 and target.sum() == 0:\n",
    "        return 1.0\n",
    "    if pred.sum() == 0 or target.sum() == 0:\n",
    "        return 0.0\n",
    "\n",
    "    pred_boundary = get_boundary(pred)\n",
    "    target_boundary = get_boundary(target)\n",
    "\n",
    "    dt_pred = distance_transform_edt(~pred_boundary)\n",
    "    dt_target = distance_transform_edt(~target_boundary)\n",
    "\n",
    "    match_pred = target_boundary & (dt_pred <= tolerance)\n",
    "    match_target = pred_boundary & (dt_target <= tolerance)\n",
    "\n",
    "    precision = match_target.sum() / (pred_boundary.sum() + 1e-8)\n",
    "    recall = match_pred.sum() / (target_boundary.sum() + 1e-8)\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "\n",
    "    bf_score = 2 * precision * recall / (precision + recall)\n",
    "    return bf_score\n",
    "\n",
    "def compute_mean_bf_score(preds, targets, tolerance=2):\n",
    "    scores = []\n",
    "    for i in range(preds.shape[0]):\n",
    "        pred = preds[i, 0].astype(np.bool_)\n",
    "        target = targets[i, 0].astype(np.bool_)\n",
    "        score = compute_bf_score_single(pred, target, tolerance)\n",
    "        scores.append(score)\n",
    "    return float(np.mean(scores)) if scores else -1.0\n",
    "\n",
    "# --- Hausdorff Distance ---\n",
    "def compute_hausdorff(preds, targets):\n",
    "    mean_hd, max_hd = [], []\n",
    "    for i in range(preds.shape[0]):\n",
    "        p = preds[i, 0].astype(np.bool_)\n",
    "        t = targets[i, 0].astype(np.bool_)\n",
    "\n",
    "        pred_boundary = get_boundary(p)\n",
    "        target_boundary = get_boundary(t)\n",
    "\n",
    "        p_coords = np.argwhere(pred_boundary)\n",
    "        t_coords = np.argwhere(target_boundary)\n",
    "\n",
    "        if p_coords.size == 0 or t_coords.size == 0:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            hd1 = directed_hausdorff(p_coords, t_coords)[0]\n",
    "            hd2 = directed_hausdorff(t_coords, p_coords)[0]\n",
    "            max_hd.append(max(hd1, hd2))\n",
    "\n",
    "            dist1 = cdist(p_coords, t_coords).min(axis=1)\n",
    "            dist2 = cdist(t_coords, p_coords).min(axis=1)\n",
    "            mean_hd.append((dist1.mean() + dist2.mean()) / 2)\n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"Hausdorff calculation failed: {e}\")\n",
    "\n",
    "    return (\n",
    "        float(np.nanmean(mean_hd)) if mean_hd else -1.0,\n",
    "        float(np.nanmean(max_hd)) if max_hd else -1.0,\n",
    "    )\n",
    "\n",
    "# --- Per-class metrics ---\n",
    "def compute_class_metrics(y_true, y_pred, class_val, epsilon=1e-7):\n",
    "    cls_pred = (y_pred == class_val)\n",
    "    cls_true = (y_true == class_val)\n",
    "\n",
    "    TP = np.sum(cls_pred & cls_true)\n",
    "    TN = np.sum(~cls_pred & ~cls_true)\n",
    "    FP = np.sum(cls_pred & ~cls_true)\n",
    "    FN = np.sum(~cls_pred & cls_true)\n",
    "\n",
    "    accuracy = TP / (TP + FN + epsilon)\n",
    "    iou = TP / (TP + FP + FN + epsilon)\n",
    "    \n",
    "    dice = (2 * TP) / (2 * TP + FP + FN + epsilon)\n",
    "    precision = TP / (TP + FP + epsilon)\n",
    "    recall = TP / (TP + FN + epsilon)\n",
    "    f1_score = (2 * precision * recall) / (precision + recall + epsilon)\n",
    "\n",
    "    return accuracy, iou, dice, precision, recall, f1_score, TP, FP, FN\n",
    "\n",
    "# --- Main Metric Function ---\n",
    "def calculate_all_metrics(predictions, targets, threshold=0.5):\n",
    "    # Ensure shape is [B, H, W]\n",
    "    if predictions.ndim == 4 and predictions.shape[1] == 1:\n",
    "        predictions = predictions[:, 0]\n",
    "    if targets.ndim == 4 and targets.shape[1] == 1:\n",
    "        targets = targets[:, 0]\n",
    "\n",
    "    assert predictions.shape == targets.shape and predictions.ndim == 3, \"Expecting [B, H, W] for both predictions and targets\"\n",
    "\n",
    "\n",
    "    probs = torch.sigmoid(predictions)\n",
    "    preds_bin = (probs > threshold).int()\n",
    "    \n",
    "    preds_np = preds_bin.cpu().numpy()\n",
    "    targets_np = targets.cpu().numpy()\n",
    "\n",
    "    y_true_flat = targets_np.flatten()\n",
    "    y_pred_flat = preds_np.flatten()\n",
    "\n",
    "    global_acc = np.sum(y_pred_flat == y_true_flat) / len(y_true_flat)\n",
    "\n",
    "    class_ids = [0, 1]\n",
    "    class_accuracies, class_ious, class_dices = [], [], []\n",
    "    class_precisions, class_recalls, class_f1s = [], [], []\n",
    "    weighted_ious = []\n",
    "    TP_sum, FP_sum, FN_sum = 0, 0, 0\n",
    "\n",
    "    for cls in class_ids:\n",
    "        acc, iou, dice, prec, rec, f1, TP, FP, FN = compute_class_metrics(y_true_flat, y_pred_flat, cls)\n",
    "        class_accuracies.append(acc)\n",
    "        class_ious.append(iou)\n",
    "        class_dices.append(dice)\n",
    "        class_precisions.append(prec)\n",
    "        class_recalls.append(rec)\n",
    "        class_f1s.append(f1)\n",
    "        class_px_count = np.sum(y_true_flat == cls)\n",
    "        weighted_ious.append(iou * class_px_count)\n",
    "        TP_sum += TP\n",
    "        FP_sum += FP\n",
    "        FN_sum += FN\n",
    "\n",
    "    mean_acc = np.mean(class_accuracies)\n",
    "    mean_iou = np.mean(class_ious)\n",
    "    weighted_iou = np.sum(weighted_ious) / (len(y_true_flat) + 1e-7)\n",
    "    mean_dice = np.mean(class_dices)\n",
    "    mean_precision = np.mean(class_precisions)\n",
    "    mean_recall = np.mean(class_recalls)\n",
    "\n",
    "    mean_bf_score = compute_mean_bf_score(preds_np, targets_np)\n",
    "    mean_hd, max_hd = compute_hausdorff(preds_np, targets_np)\n",
    "\n",
    "    try:\n",
    "        probs_flat = probs.detach().cpu().numpy().flatten()\n",
    "        if len(np.unique(y_true_flat)) > 1:\n",
    "            auroc = roc_auc_score(y_true_flat, probs_flat)\n",
    "        else:\n",
    "            auroc = 0.5\n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"AUROC computation failed: {e}\")\n",
    "        auroc = 0.5\n",
    "\n",
    "    return {\n",
    "        \"GlobalAccuracy\": global_acc,\n",
    "        \"MeanAccuracy\": mean_acc,\n",
    "        \"MeanIoU\": mean_iou,\n",
    "        \"WeightedIoU\": weighted_iou,\n",
    "        \"MeanBFScore\": mean_bf_score,\n",
    "        \"Dice (F1 Score)\": mean_dice,\n",
    "        \"AUROC\": auroc,\n",
    "        \"Precision\": mean_precision,\n",
    "        \"Recall\": mean_recall,\n",
    "        \"MeanHausdorff\": mean_hd,\n",
    "        \"MaxHausdorff\": max_hd,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown\n",
    "# url = 'https://drive.google.com/uc?id=FILE_ID_OR_FULL_URL'\n",
    "# gdown.download(url, 'model.pth', quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_original(img, final_width=1024, final_height=256, cropped_width=750, cropped_height=554):\n",
    "    # Step 1: Resize back to cropped size\n",
    "    img_resized = TF.resize(img, [cropped_height, cropped_width], interpolation=Image.NEAREST)\n",
    "\n",
    "    # Step 2: Pad to original size\n",
    "    pad_left = (final_width - cropped_width) // 2\n",
    "    pad_right = final_width - cropped_width - pad_left\n",
    "    pad_top = (final_height - cropped_height) // 2\n",
    "    pad_bottom = final_height - cropped_height - pad_top\n",
    "\n",
    "    img_padded = ImageOps.expand(img_resized, (pad_left, pad_top, pad_right, pad_bottom), fill=0)\n",
    "\n",
    "    return img_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "\n",
    "# --- Test Setup ---\n",
    "test_images = sorted(glob.glob('../Data/US_Test_2023April7/*.jpg'))\n",
    "test_labels = sorted(glob.glob('../Data/Labels_Test_2023April7/*.png'))\n",
    "test_dataset = BubbleDataset(test_images, test_labels, augment=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_pulse_and_dataset(filename):\n",
    "    \"\"\"\n",
    "    Extracts:\n",
    "    - pulse number from 'US###'\n",
    "    - dataset number as the last number before '.jpg'\n",
    "    Example: 't3US100_738983_1.jpg' → pulse=100, dataset=1\n",
    "    \"\"\"\n",
    "    base = os.path.basename(filename).replace(\".jpg\", \"\")\n",
    "    parts = base.split('_')\n",
    "    dataset = int(parts[-1]) if parts[-1].isdigit() else -1\n",
    "    pulse_match = re.search(r'US(\\d+)', base)\n",
    "    pulse = int(pulse_match.group(1)) if pulse_match else -1\n",
    "    return pulse, dataset\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# STEP 1: Create test dataset\n",
    "test_images = sorted(glob.glob('../Data/US_Test_2023April7/*.jpg'))\n",
    "test_labels = sorted(glob.glob('../Data/Label_Test_2023April7/*.png'))\n",
    "\n",
    "\n",
    "test_dataset = BubbleDataset(test_images, test_labels, augment=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size= 16, shuffle=False)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "from time import perf_counter\n",
    "\n",
    "\n",
    "\n",
    "def compute_area(mask):\n",
    "    return (mask == 1).sum().item()\n",
    "\n",
    "\n",
    "# Function to compute per-class IoU\n",
    "def compute_class_iou(preds, targets, num_classes):\n",
    "    ious = []\n",
    "    total_intersection = 0\n",
    "    total_union = 0\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (preds == cls)\n",
    "        target_inds = (targets == cls)\n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        union = (pred_inds | target_inds).sum().item()\n",
    "\n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # Undefined IoU\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "            total_intersection += intersection\n",
    "            total_union += union\n",
    "\n",
    "    mean_iou = np.nanmean(ious)\n",
    "    weighted_iou = total_intersection / total_union if total_union != 0 else float('nan')\n",
    "\n",
    "    return {\n",
    "        'per_class_iou': ious,\n",
    "        'mean_iou': mean_iou,\n",
    "        'weighted_iou': weighted_iou\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# === Load best model === #\n",
    "model.load_state_dict(torch.load(\"best_model_final.pth\"))\n",
    "model.eval()\n",
    "# checkpoint = torch.load(\"../code_files/checkpoints/TorchvisionDeepLabV3_DiceFocalLoss_Dice0.5_Tversky0.5_Focal0.6_Epochs5_LR0.0003/best.pth.tar\")\n",
    "# model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "# model.eval()\n",
    "\n",
    "\n",
    "# === Run on val_loader === #\n",
    "# Evaluation\n",
    "records = []\n",
    "all_mean_ious = []\n",
    "total_intersection = 0\n",
    "total_union = 0\n",
    "n_visualize = 5  # Change as needed\n",
    "\n",
    "\n",
    "all_samples = []\n",
    "# === Evaluation Loop ===\n",
    "start_time = perf_counter()\n",
    "with torch.no_grad():\n",
    "    for idx, (imgs, masks) in enumerate(tqdm(test_loader, desc=\"Evaluating on Test\")):\n",
    "        imgs, masks = imgs.cuda(), masks.cuda()\n",
    "        \n",
    "        outputs = model(imgs)['out']\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        # preds = recover_original(preds)\n",
    "        # masks = recover_original(masks)\n",
    "\n",
    "        if preds.shape != masks.shape:\n",
    "            preds = F.interpolate(preds.unsqueeze(1).float(), size=masks.shape[-2:], mode='nearest').squeeze(1).long()\n",
    "\n",
    "        recovered_preds = torch.stack([\n",
    "            TF.to_tensor(recover_original(TF.to_pil_image(pred.cpu().byte() * 255))).squeeze(0).long()\n",
    "            for pred in preds\n",
    "        ])\n",
    "\n",
    "        recovered_masks = torch.stack([\n",
    "            TF.to_tensor(recover_original(TF.to_pil_image(mask.cpu().byte() * 255))).squeeze(0).long()\n",
    "            for mask in masks\n",
    "        ])\n",
    "\n",
    "        \n",
    "        # Compute IoU metrics\n",
    "        iou_metrics = compute_class_iou(recovered_preds.cpu().numpy(), recovered_masks.cpu().numpy(), num_classes=2)\n",
    "        all_mean_ious.append(iou_metrics['mean_iou'])\n",
    "\n",
    "        total_intersection += iou_metrics['weighted_iou'] * (recovered_preds == 1).sum().item()\n",
    "        total_union += (recovered_preds == 1).sum().item()\n",
    "\n",
    "        for i in range(imgs.size(0)):\n",
    "            image_name = os.path.basename(test_images[idx * test_loader.batch_size + i])\n",
    "            pulse, dataset = extract_pulse_and_dataset(image_name)\n",
    "\n",
    "            gt_area = compute_area(recovered_masks[i].cpu())\n",
    "            pred_area = compute_area(recovered_preds[i].cpu())\n",
    "\n",
    "            # === Main Metric Computation ===\n",
    "            pred = preds[i].unsqueeze(0).cpu()\n",
    "            target = masks[i].unsqueeze(0).cpu()\n",
    "            metrics = calculate_all_metrics(pred, target)\n",
    "            all_samples.append((pred, target)) ########\n",
    "\n",
    "            # Store everything\n",
    "            records.append({\n",
    "                'image': image_name,\n",
    "                'pulse': pulse,\n",
    "                'dataset': dataset,\n",
    "                'gt_area_px': gt_area,\n",
    "                'pred_area_px': pred_area,\n",
    "                **metrics\n",
    "            })\n",
    "\n",
    "            # records.append({\n",
    "            #     'image': image_name,\n",
    "            #     'pulse': pulse,\n",
    "            #     'dataset': dataset,\n",
    "            #     'gt_area_px': gt_area,\n",
    "            #     'pred_area_px': pred_area\n",
    "            # })\n",
    "\n",
    "end_time = perf_counter()\n",
    "total_inference_time = end_time - start_time\n",
    "print(f\"Total Inference Time: {total_inference_time:.2f} seconds\")\n",
    "\n",
    "final_mean_iou = np.mean(all_mean_ious)\n",
    "final_weighted_iou = total_intersection / total_union if total_union > 0 else float('nan')\n",
    "\n",
    "print(f\"Mean IoU (unweighted)   : {final_mean_iou:.4f}\")\n",
    "print(f\"Weighted IoU (area)     : {final_weighted_iou:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Aggregate Metrics ---\n",
    "all_preds = torch.stack([s[0].squeeze(0) for s in all_samples])   \n",
    "all_targets = torch.stack([s[1] for s in all_samples])            \n",
    "\n",
    "final_metrics = calculate_all_metrics(all_preds, all_targets)\n",
    "# print(final_metrics)\n",
    "print(\"\\n--- Average Test Metrics ---\")\n",
    "if final_metrics:\n",
    "    for k, v in sorted(final_metrics.items()):\n",
    "        print(f\"{k}: {v:.4f}\" if isinstance(v, (float, np.number)) and pd.notna(v) else f\"{k}: {v}\")\n",
    "        \n",
    "# === Convert to DataFrame ===\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Convert to mm² using correct scaling\n",
    "pixel_area_mm2 = 0.0025\n",
    "df['gt_area_mm2'] = df['gt_area_px'] * pixel_area_mm2\n",
    "df['pred_area_mm2'] = df['pred_area_px'] * pixel_area_mm2\n",
    "\n",
    "# === Show first few entries for verification ===\n",
    "print(\"✅ Evaluation complete. Sample entries:\")\n",
    "display(df.head())\n",
    "\n",
    "# === Save to CSV ===\n",
    "df.to_csv(\"gt_pred_areas_per_image.csv\", index=False)\n",
    "print(\"✅ Saved: gt_pred_areas_per_image.csv\")\n",
    "\n",
    "# === Optional: Group by (pulse, dataset) for plotting later ===\n",
    "grouped_df = df.groupby(['pulse', 'dataset'])[['gt_area_mm2', 'pred_area_mm2']].mean().reset_index()\n",
    "grouped_df.to_csv(\"area_grouped_by_pulse_dataset.csv\", index=False)\n",
    "print(\"✅ Saved: area_grouped_by_pulse_dataset.csv\")\n",
    "\n",
    "\n",
    "\n",
    "display(grouped_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Ensure area in mm² is available\n",
    "# pixel_area_mm2 = 0.005\n",
    "# df['gt_area_mm2'] = df['gt_area_px'] * pixel_area_mm2\n",
    "# df['pred_area_mm2'] = df['pred_area_px'] * pixel_area_mm2\n",
    "\n",
    "# Group by pulse and calculate mean and std across datasets\n",
    "pulse_agg = df.groupby('pulse')[['gt_area_mm2', 'pred_area_mm2']].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "pulse_agg.columns = ['pulse',\n",
    "                     'gt_mean', 'gt_std',\n",
    "                     'pred_mean', 'pred_std']\n",
    "# display(pulse_agg)\n",
    "\n",
    "pulse_agg['pulse'] = pulse_agg['pulse'].astype(int)*20\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming pulse_agg is already defined as your DataFrame\n",
    "# If not, you can load it from CSV or another source\n",
    "\n",
    "# Plot setup\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "\n",
    "plt.errorbar(\n",
    "    pulse_agg['pulse'], pulse_agg['pred_mean'], yerr=pulse_agg['pred_std'],\n",
    "    fmt='-o', label='Prediction', color='#439cce', capsize=3, alpha=0.7\n",
    ")\n",
    "\n",
    "plt.errorbar(\n",
    "    pulse_agg['pulse'], pulse_agg['gt_mean'], yerr=pulse_agg['gt_std'],\n",
    "    fmt='-o', label='Ground Truth', color='#ba4000', capsize=3, alpha=0.7\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel('Number of Pulses')\n",
    "plt.ylabel('Ablation Area (mm²)')\n",
    "plt.title('Ablation Area vs Number of Pulses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Group by pulse and calculate mean and std across datasets\n",
    "pulse_agg = df.groupby('pulse')[['gt_area_mm2', 'pred_area_mm2']].agg(['mean', 'std']).reset_index()\n",
    "pulse_agg.columns = ['pulse', 'gt_mean', 'gt_std', 'pred_mean', 'pred_std']\n",
    "pulse_agg['pulse'] = pulse_agg['pulse'].astype(int) * 20\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 5))\n",
    "ax = plt.gca()\n",
    "ax.tick_params(direction='in') \n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(1.5)  # or 2.0 for thicker\n",
    "\n",
    "\n",
    "# CNN Prediction (blue)\n",
    "plt.scatter(pulse_agg['pulse'], pulse_agg['pred_mean'], color='#0072ba', label='CNN', s=25)\n",
    "plt.fill_between(\n",
    "    pulse_agg['pulse'],\n",
    "    pulse_agg['pred_mean'] - pulse_agg['pred_std'],\n",
    "    pulse_agg['pred_mean'] + pulse_agg['pred_std'],\n",
    "    color='#0072ba', alpha=0.4\n",
    ")\n",
    "plt.plot(\n",
    "    pulse_agg['pulse'], pulse_agg['pred_mean'] - pulse_agg['pred_std'],\n",
    "    color='black', linewidth=0.3\n",
    ")\n",
    "plt.plot(\n",
    "    pulse_agg['pulse'], pulse_agg['pred_mean'] + pulse_agg['pred_std'],\n",
    "    color='black', linewidth=0.3\n",
    ")\n",
    "\n",
    "\n",
    "# Ground Truth (reddish)\n",
    "plt.scatter(pulse_agg['pulse'], pulse_agg['gt_mean'], color='#ba4000', label='Truth', s=40, marker='^')\n",
    "plt.fill_between(\n",
    "    pulse_agg['pulse'],\n",
    "    pulse_agg['gt_mean'] - pulse_agg['gt_std'],\n",
    "    pulse_agg['gt_mean'] + pulse_agg['gt_std'],\n",
    "    color='#ba4000', alpha=0.4\n",
    ")\n",
    "plt.plot(\n",
    "    pulse_agg['pulse'], pulse_agg['gt_mean'] - pulse_agg['gt_std'],\n",
    "    color='black', linewidth=0.3\n",
    ")\n",
    "plt.plot(\n",
    "    pulse_agg['pulse'], pulse_agg['gt_mean'] + pulse_agg['gt_std'],\n",
    "    color='black', linewidth=0.3\n",
    ")\n",
    "\n",
    "# Labels, Title, Legend\n",
    "plt.xlabel('Number of Pulses', fontsize=20, fontweight='bold')\n",
    "plt.ylabel('Ablation Area (mm²)', fontsize=20, fontweight='bold')\n",
    "\n",
    "# plt.title('Ablation Area vs Number of Pulses')\n",
    "# plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.xlim(0, 2000)\n",
    "plt.ylim(0, 120)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics_vs_pulses(metrics_csv_path, save_dir, experiment_name):\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Load and preprocess\n",
    "    metrics_df = pd.read_csv(metrics_csv_path)\n",
    "    if 'pulse' in metrics_df.columns:\n",
    "        metrics_df = metrics_df.rename(columns={'pulse': 'pulses'})\n",
    "\n",
    "    metrics_to_plot = {\n",
    "        \"GlobalAccuracy\": \"Predictive Accuracy (%)\",\n",
    "        \"Dice (F1 Score)\": \"Dice Similarity Coefficient (%)\"\n",
    "    }\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "\n",
    "    for idx, (metric, ylabel) in enumerate(metrics_to_plot.items()):\n",
    "        ax = axes[idx]\n",
    "\n",
    "        if metric not in metrics_df.columns:\n",
    "            print(f\"Warning: Metric '{metric}' not found in DataFrame columns.\")\n",
    "            continue\n",
    "\n",
    "        grouped = metrics_df.groupby('pulses')[metric].agg(['mean', 'std']).reset_index().sort_values(by='pulses')\n",
    "        grouped['mean'] *= 100\n",
    "        grouped['std'] *= 100\n",
    "\n",
    "        # === Styling Consistency ===\n",
    "        ax.tick_params(direction='in')\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_linewidth(1.5)\n",
    "\n",
    "        # === Plot scatter + fill_between ===\n",
    "        ax.scatter(grouped['pulses'], grouped['mean'], color='#0071bd', s=25, alpha=0.9, edgecolors='black', linewidths=0.3)\n",
    "        ax.fill_between(grouped['pulses'],\n",
    "                        grouped['mean'] - grouped['std'],\n",
    "                        grouped['mean'] + grouped['std'],\n",
    "                        color='#0071bd', alpha=0.4)\n",
    "        ax.plot(grouped['pulses'], grouped['mean'] - grouped['std'], color='black', linewidth=0.3)\n",
    "        ax.plot(grouped['pulses'], grouped['mean'] + grouped['std'], color='black', linewidth=0.3)\n",
    "\n",
    "        ax.set_xlabel('Number of Pulses', fontsize=20, fontweight='bold')\n",
    "        ax.set_ylabel(ylabel, fontsize=20, fontweight='bold')\n",
    "        # True range of your pulses (actual data range)\n",
    "        actual_min = grouped['pulses'].min()\n",
    "        actual_max = grouped['pulses'].max()\n",
    "\n",
    "        # Create 5 evenly spaced positions across actual data\n",
    "        tick_positions = np.linspace(actual_min, actual_max, 5)\n",
    "        tick_labels = np.linspace(0, 2000, 5).astype(int)\n",
    "\n",
    "        ax.set_xticks(tick_positions)\n",
    "        ax.set_xticklabels(tick_labels)\n",
    "\n",
    "\n",
    "        ax.grid(True, linestyle='--', alpha=0.5)\n",
    "        # ax.set_xlim(0, 2000)\n",
    "        ax.set_ylim(0, 100)\n",
    "\n",
    "\n",
    "    # Super Title\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"{experiment_name} Metrics vs. Number of Pulses\", fontsize=16, fontweight='bold', y=1.02)\n",
    "    \n",
    "    # Save\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    plot_path = os.path.join(save_dir, f\"{experiment_name}_metrics_vs_pulses.png\")\n",
    "    plt.savefig(plot_path, dpi=200, bbox_inches='tight')\n",
    "    print(f\"✅ Metrics plot saved to {plot_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics_vs_pulses(\n",
    "    metrics_csv_path=\"test_metrics_per_image.csv\",\n",
    "    save_dir=\"this_studio\",\n",
    "    experiment_name=\"BubbleSeg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
